{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ongoing-headquarters",
   "metadata": {},
   "source": [
    "# *Growth Profiler* Data Analysis\n",
    "\n",
    "The *Growth Profiler* is a high throughput device for growth characterization. Growth is automatically measured via OD in 96-well plates and the results are stored in csv files. This workflow trains analysis of growth data in csv format.\n",
    "\n",
    "## Loading libraries\n",
    "There are some general Python libraries necessary in order to have useful functions available. The library responsible for growth curve analysis is `batchslopes` [Link](https://github.com/uliebal/gp_analytics) and contains functions specifically designed for analysis of the *Growth Profiler*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from iambcodes.bsfun import *\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "# warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "# from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-referral",
   "metadata": {},
   "source": [
    "## Data input and descripion\n",
    "\n",
    "The standard growth profiler csv file contains in the first rows some general information on the experimental conditions. We ignore these metadata in the regression analysis, however, make sure to include the header names when the real data starts. The first column should contain the time measurements, and all other columns are OD values. The *Growth Profiler* usually measures the time in minutes, other experimental data, like in *RecExpSim*, uses hours as time unit. The workflow tries to unify the time-based analysis by dividing the time vector with the variable `TimeUnit`.\n",
    "\n",
    "The data is partitioned (binned, variable `Partition`) and in each bin a regression on the logarithmic data is conducted. The bin with the best correlation coefficient is then selected for further partitioning until the correlation coefficient gets worse (is decreasing). The correlation coefficient and the corresponding slope of the logarithmic OD are reported.\n",
    "\n",
    "**Important**: Check the decimal separator. Science typically works with the english convention of point-separators (`10,000.23`), but the *Growth Profiler* or your local system might generate an csv with german comma-separators (`10.000,23`).\n",
    "\n",
    "\n",
    "**Input:**\n",
    " - `File`: string, growth experiment csv-file name\n",
    " - `skiprows`: integer, lines of experimental metadata, Start counting from 0.\n",
    " - `decimal`: string ('.' or ','), decimal separator \n",
    " - `TimeUnit`: integer, for measure time in minutes: 60, hours: 1\n",
    " - `Partition`: integer, decides the number of bins on which regression is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = 'GP_20211027_135336_GValue.csv'        #either '../data' or a single csv e.g. 'list1.csv'\n",
    "\n",
    "morecsv = Foldertest(Name)\n",
    "\n",
    "if morecsv == 1:\n",
    "    myFiles = Batchfilenames(Name)\n",
    "else:\n",
    "    myFiles = Name\n",
    "\n",
    "myFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name = 'list5.csv'       #GP_20210507_171028_MTP03_GValue\n",
    "\n",
    "Source = 1   #1 is real GrowthProfiler, 0 is synthetic data\n",
    "\n",
    "repnum = 3                 #number of experiments in replicates\n",
    "GVexp = 1\n",
    "eexp = 0\n",
    "\n",
    "Partition = 4\n",
    "\n",
    "FileName = 'list3.csv'\n",
    "WellID = 'A1'\n",
    "\n",
    "if not isinstance(myFiles, str):\n",
    "    index = [idx for idx, s in enumerate(myFiles) if FileName in s][0]\n",
    "else:\n",
    "    File = myFiles\n",
    "\n",
    "myparams = Fileparams(Source)\n",
    "\n",
    "#pd.options.display.max_rows\n",
    "\n",
    "if isinstance(myFiles, str):\n",
    "    df = pd.read_csv(File, skiprows=myparams['skiprows'] , decimal=myparams['decimal'], sep = \",\", index_col='Time (min)')\n",
    "else:\n",
    "    print('{}, {}'.format(FileName, WellID))\n",
    "    df = pd.read_csv(myFiles[index][5:], skiprows=myparams['skiprows'] , decimal=myparams['decimal'], sep = \",\", index_col='Time (min)')\n",
    "    \n",
    "\n",
    "if 'Input_Image' in list(df.columns):\n",
    "    df = df.drop(labels='Input_Image', axis=1)\n",
    "df.index = df.index/myparams['TimeUnit']\n",
    "OD = pd.DataFrame()\n",
    "myCols = df.columns\n",
    "for i1 in myCols: \n",
    "    OD[i1] = CorrectedOD(df[i1], GVexp, eexp)\n",
    "TimeAx = df.index #'Time (min)' # for growth profiler\n",
    "Exp0 = df.index\n",
    "\n",
    "for column in df.columns:\n",
    "    if 'Unnamed' in column:\n",
    "        df.drop(labels= column, axis=1, inplace=True)\n",
    "        \n",
    "# print('Column headers: ', df.columns)\n",
    "# df.plot(x=TimeAx, y=Exp0)\n",
    "df[WellID].plot()\n",
    "\n",
    "\n",
    "#plt.savefig('myPlots.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-hydrogen",
   "metadata": {},
   "source": [
    "## All Experiment Analysis\n",
    "\n",
    "Below, all experiments in the csv file are analysed. The final information is stored in plots showing the regression range for each experiment along with the growth rate and the correlation coefficient and stored as `myPlots.svg`. If the regressions look unconvincing, try a different partition.\n",
    "\n",
    "By doubleclicking on the subplots, you can zoom in for better visual recognition.\n",
    "\n",
    "In this next section, analyzed data will be stored as Excel file(s) in the same folder, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(myFiles, str):\n",
    "\n",
    "    myCols = df.columns\n",
    "    subplot_x = round(np.sqrt(len(myCols)))\n",
    "    subplot_y = round(np.sqrt(len(myCols))) + 1\n",
    "    \n",
    "#     myr2table = pd.DataFrame()\n",
    "    mu_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    NumExp = len(myCols)\n",
    "    AxDim = np.ceil(np.sqrt(NumExp))\n",
    "    t = df.index.values\n",
    "# plt.subplots(AxDim, AxDim, sharex='col')\n",
    "    fig, ax = plt.subplots(figsize=[20,10], sharey=True)\n",
    "    print(myCols)\n",
    "    for idx, myExp in enumerate(myCols):\n",
    "#print(myExp)\n",
    "        x = OD[myExp].values\n",
    "        myResult = DetectR2MaxSingle(t,x,Partition)\n",
    "        plt.subplot(subplot_x, subplot_y, idx+1)\n",
    "        plt.plot(t, np.log(x))\n",
    "        plt.title(myExp)\n",
    "        if myResult is not False:\n",
    "            plt.scatter(myResult['time'], np.log(myResult['OD']))\n",
    "            if Source == 1:\n",
    "                plt.plot(myResult['time'], myResult['Slope']*myResult['time'] + myResult['ycorrect'], 'r', label='$\\mu$:{:.3f}, R2:{:.2f}'.format(myResult['Slope']*60, myResult['R2']))\n",
    "            else:\n",
    "                plt.plot(myResult['time'], myResult['Slope']*myResult['time'] + myResult['ycorrect'], 'r', label='$\\mu$:{:.3f}, R2:{:.2f}'.format(myResult['Slope'], myResult['R2']))\n",
    "            myResult['ID'] = myExp\n",
    "            plt.legend()\n",
    "        #hier Dataframe f√ºr Mu und R2 feeden\n",
    "            mu_list.append(myResult['Slope'])\n",
    "            r2_list.append(myResult['R2'])\n",
    "        if myResult is False:\n",
    "            mu_list.append(False)\n",
    "            r2_list.append(False)\n",
    "        plt.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    \n",
    "    fig.text(0.5, 0.1, 'time', ha='center')\n",
    "    fig.text(0.1, 0.5, 'ln(OD)', va='center', rotation='vertical')\n",
    "    means, stdev = StatsCalc(OD, repnum)\n",
    "    tk = 1\n",
    "    createExcelFiles(tk, means, stdev, myCols, mu_list, r2_list, repnum, df, OD, myFiles)\n",
    "else:\n",
    "    df = {}\n",
    "    mu = {}\n",
    "    r2 = {}\n",
    "    myr2table = pd.DataFrame()\n",
    "    with pd.ExcelWriter('myr2table.xlsx') as writer:  \n",
    "        myr2table.to_excel(writer, sheet_name='x')\n",
    "    myr2table = pd.DataFrame()\n",
    "    for i in range(len(myFiles)):\n",
    "        df[i] = pd.read_csv(myFiles[i][5:], skiprows=myparams['skiprows'] , decimal=myparams['decimal'], sep = \",\", index_col = 'Time (min)')\n",
    "        if 'Input_Image' in df[i].columns:\n",
    "            df [i] = df[i].drop(labels='Input_Image', axis=1)\n",
    "        if 'Unnamed: 25' in df[i].columns:\n",
    "            df [i] = df[i].drop(labels='Unnamed: 25', axis=1)\n",
    "        myCols = df[i].columns\n",
    "        OD = pd.DataFrame()\n",
    "        for i1 in myCols:\n",
    "            OD = CorrectedOD(df[i], GVexp, eexp)\n",
    "        mu_list = []\n",
    "        r2_list = []\n",
    "        NumExp = len(myCols)\n",
    "        AxDim = np.ceil(np.sqrt(NumExp))\n",
    "        t = df[i].index.values\n",
    "        for idx, myExp in enumerate(myCols):\n",
    "            x = OD[myExp].values\n",
    "            myResult = DetectR2MaxSingle(t,x,Partition)\n",
    "            if myResult is not False:\n",
    "                myResult['ID'] = myExp\n",
    "                mu_list.append(myResult['Slope'])\n",
    "                r2_list.append(myResult['R2'])\n",
    "            if myResult is False:\n",
    "                mu_list.append(False)\n",
    "                r2_list.append(False)\n",
    "        mu[i] = mu_list\n",
    "        r2[i] = r2_list\n",
    "        myr2table['Wells'] = myCols\n",
    "        myr2table['Mu value'] = mu[i]\n",
    "        myr2table['R2 value'] = r2[i]\n",
    "        \n",
    "    means, stdev = StatsCalc(OD, repnum)\n",
    "    for tk in range(len(myFiles)):\n",
    "        createExcelFiles(tk, means, stdev, myCols, mu_list, r2_list, repnum, df, OD, myFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-subdivision",
   "metadata": {},
   "source": [
    "## Single Experiment Analysis\n",
    "\n",
    "Below, we check individual growth curves and their regression. This can be helpful if you want to examine a particular experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df.index.values\n",
    "x = df[WellID].values  # instead of WellID, one can as well directly search after 'A1', 'B3', etc. for example. \n",
    "\n",
    "\n",
    "myResult = DetectR2MaxSingle(t,x,Partition)\n",
    "# print(myResult)\n",
    "plt.plot(t, np.log(x))\n",
    "if myResult!=False:\n",
    "    plt.scatter(myResult['time'], np.log(myResult['OD']))\n",
    "    plt.plot(myResult['time'], myResult['Slope']*myResult['time'] + myResult['ycorrect'], 'r', label='$\\mu$:{:.3f}, R2:{:.2f}'.format(myResult['Slope'], myResult['R2']))\n",
    "    plt.legend()\n",
    "    myResult['ID'] = Exp0\n",
    "# myResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-crest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-premium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yield = 0.78\n",
    "InitSubsConc = 50\n",
    "sample = pd.DataFrame()\n",
    "sample = df.iloc[:, 0]\n",
    "mylist = [InitSubsConc]\n",
    "for indx in range(1, len(df['A1'])-1):\n",
    "    BiomassDiff = df.loc[df.index[indx], 'A1']-df.loc[df.index[indx-1], 'A1']\n",
    "    if BiomassDiff < 0:\n",
    "        BiomassDiff = 0\n",
    "    SubsUptake = mylist[-1]-(BiomassDiff/Yield)\n",
    "    mylist.append(SubsUptake)\n",
    "mylist.append(SubsUptake)\n",
    "mylist\n",
    "columnsample = pd.DataFrame({'Substrate Uptake':mylist}, index = df.index)\n",
    "# columnsample.plot()\n",
    "# sample['Substrate'] = mylist\n",
    "sample = pd.concat([sample, columnsample], axis=1)\n",
    "# type(sample)\n",
    "sample.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iambjudas",
   "language": "python",
   "name": "iambjudas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
